parquet : 열 기준으로 정리, 데이터 형식 통일되어 압축하여 보기에 편함
                 그냥 csv 형태에 비해 메모리 덜 잡아먹음 but 별도 프로그램 필요. 일반적으로 csv파일 보다 크기가 작지만 용량이 작은 경우 메타데이터를 지니고 있어 csv파일 보다 클 수도
                 있다.
downcast: 도메인 값의 최대치를 고려하여 저장공간의 최적화를 위해 더 적은 공간을 사용 하는 방향으로 형 변환 시켜주는 파라미터 pd.to_numeric(Series, erroes='', downcast='')
          int : unsigned ( * signed/unsigned 차이ex) int8 일때, signed는 부호가 있어서 표현 범위가 -128 부터 127 까지라면, 
                unsigned는 부호가 없어서 0부터 255까지 표현할 수 있는 것 (둘의 표현 크기는 같지만 범위가 다른 것!)
          float : float
          bool : int8
          object : category
          pd.to_numeric(df[col], downcast="")
<error 종류>(pd.to_numeric)
    1) errors = 'ignore' 
    -> 만약 숫자로 변경할 수 없는 데이터라면 숫자로 변경하지 않고 원본 데이터를 그대로 반환
    2) errors = 'coerce' 
    -> 만약 숫자로 변경할 수 없는 데이터라면 기존 데이터를 지우고 NaN으로 설정하여 반환
    3) errors = 'raise' 
    -> 만약 숫자로 변경할 수 없는 데이터라면 에러를 일으키며 코드를 중단

Apache Spark = 빅데이터 분산처리 플랫폼
pyspark = 파이썬환경에서 쓸 수 있게해주는 인터페이스
koalas: pyspark에서 사용하는 대용량 관리 툴, pandas보다 더 큰 데이터를 분석할 수 있는 툴
plotly = 한글 사용 문제 없음
df에 문제 없는데 그래프 안그려지면 orient 확인(x, y축을 바꿔보자)
그래프 그릴 때, groupby로 df 먼저 전처리 해준 뒤 그리면 훨씬 빠르게 처리 가능
cufflinks: pandas와 plotly를 이어주는 도구

Q. 왜 행 기반이 아니고 열 기반 저장 형식을 사용하면 용량이 더 줄어들까?
 - 열 기반으로 저장하면 같은 형식끼리 저장이 되기 때문에 압축률이 훨씬 높다
   (int, float, object…)
